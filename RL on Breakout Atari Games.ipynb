{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a76be95c",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70231372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_atari_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee35ec4",
   "metadata": {},
   "source": [
    "# 2. Test Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387fc69f",
   "metadata": {},
   "source": [
    "### Download ROMS Atari Games\n",
    "[http://www.atarimania.com/roms/Roms.rar](http://www.atarimania.com/roms/Roms.rar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12d8b29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying bank_heist.bin from ./Roms/ROMS/Bank Heist (Bonnie & Clyde, Cops 'n' Robbers, Hold-Up, Roaring 20's) (1983) (20th Century Fox Video Games, Bill Aspromonte) (11012) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/bank_heist.bin\n",
      "copying kangaroo.bin from ./Roms/ROMS/Kangaroo (1983) (Atari - GCC, Kevin Osborn) (CX2689) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/kangaroo.bin\n",
      "copying tutankham.bin from ./Roms/ROMS/Tutankham (1983) (Parker Brothers, Dave Engman, Dawn Stockbridge) (PB5340) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/tutankham.bin\n",
      "copying video_pinball.bin from ./Roms/ROMS/Video Pinball - Arcade Pinball (1981) (Atari, Bob Smith - Sears) (CX2648 - 49-75161) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/video_pinball.bin\n",
      "copying surround.bin from ./Roms/ROMS/Surround (32 in 1) (Bit Corporation) (R320).bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/surround.bin\n",
      "copying star_gunner.bin from ./Roms/ROMS/Stargunner (1983) (Telesys, Alex Leavens) (1005) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/star_gunner.bin\n",
      "copying galaxian.bin from ./Roms/ROMS/Galaxian (1983) (Atari - GCC, Mark Ackerman, Tom Calderwood, Glenn Parker) (CX2684) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/galaxian.bin\n",
      "copying journey_escape.bin from ./Roms/ROMS/Journey Escape (1983) (Data Age, J. Ray Dettling) (112-006) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/journey_escape.bin\n",
      "copying zaxxon.bin from ./Roms/ROMS/Zaxxon (1983) (Coleco) (2454) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/zaxxon.bin\n",
      "copying lost_luggage.bin from ./Roms/ROMS/Lost Luggage (Airport Mayhem) (1982) (Apollo - Games by Apollo, Larry Minor, Ernie Runyon, Ed Salvo) (AP-2004) [no opening scene] ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/lost_luggage.bin\n",
      "copying solaris.bin from ./Roms/ROMS/Solaris (The Last Starfighter, Star Raiders II, Universe) (1986) (Atari, Douglas Neubauer, Mimi Nyden) (CX26136) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/solaris.bin\n",
      "copying carnival.bin from ./Roms/ROMS/Carnival (1982) (Coleco - Woodside Design Associates, Steve 'Jessica Stevens' Kitchen) (2468) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/carnival.bin\n",
      "copying yars_revenge.bin from ./Roms/ROMS/Yars' Revenge (Time Freeze) (1982) (Atari, Howard Scott Warshaw - Sears) (CX2655 - 49-75167) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/yars_revenge.bin\n",
      "copying up_n_down.bin from ./Roms/ROMS/Up 'n Down (1984) (SEGA - Beck-Tech, Steve Beck, Phat Ho) (009-01) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/up_n_down.bin\n",
      "copying assault.bin from ./Roms/ROMS/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/assault.bin\n",
      "copying frogger.bin from ./Roms/ROMS/Frogger (1982) (Parker Brothers, Ed English, David Lamkins) (PB5300) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/frogger.bin\n",
      "copying gopher.bin from ./Roms/ROMS/Gopher (Gopher Attack) (1982) (U.S. Games Corporation - JWDA, Sylvia Day, Todd Marshall, Robin McDaniel, Henry Will IV) (VC2001) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/gopher.bin\n",
      "copying adventure.bin from ./Roms/ROMS/Adventure (1980) (Atari, Warren Robinett) (CX2613, CX2613P) (PAL).bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/adventure.bin\n",
      "copying road_runner.bin from patched version of ./Roms/ROMS/Road Runner (1989) (Atari - Bobco, Robert C. Polaro) (CX2663) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/road_runner.bin\n",
      "copying sir_lancelot.bin from ./Roms/ROMS/Sir Lancelot (1983) (Xonox - K-Tel Software - Product Guild, Anthony R. Henderson) (99006, 6220) (PAL).bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/sir_lancelot.bin\n",
      "copying donkey_kong.bin from ./Roms/ROMS/Donkey Kong (1982) (Coleco - Woodside Design Associates - Imaginative Systems Software, Garry Kitchen) (2451) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/donkey_kong.bin\n",
      "copying qbert.bin from ./Roms/ROMS/Q-bert (1983) (Parker Brothers - Western Technologies, Dave Hampton, Tom Sloper) (PB5360) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/qbert.bin\n",
      "copying name_this_game.bin from ./Roms/ROMS/Name This Game (Guardians of Treasure) (1983) (U.S. Games Corporation - JWDA, Roger Booth, Sylvia Day, Ron Dubren, Todd Marshall, Robin McDaniel, Wes Trager, Henry Will IV) (VC1007) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/name_this_game.bin\n",
      "copying atlantis.bin from ./Roms/ROMS/Atlantis (Lost City of Atlantis) (1982) (Imagic, Dennis Koble) (720103-1A, 720103-1B, IA3203, IX-010-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/atlantis.bin\n",
      "copying centipede.bin from ./Roms/ROMS/Centipede (1983) (Atari - GCC) (CX2676) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/centipede.bin\n",
      "copying gravitar.bin from ./Roms/ROMS/Gravitar (1983) (Atari, Dan Hitchens, Mimi Nyden) (CX2685) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/gravitar.bin\n",
      "copying montezuma_revenge.bin from ./Roms/ROMS/Montezuma's Revenge - Featuring Panama Joe (1984) (Parker Brothers - JWDA, Henry Will IV) (PB5760) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/montezuma_revenge.bin\n",
      "copying jamesbond.bin from ./Roms/ROMS/James Bond 007 (James Bond Agent 007) (1984) (Parker Brothers - On-Time Software, Joe Gaucher, Louis Marbel) (PB5110) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/jamesbond.bin\n",
      "copying hero.bin from ./Roms/ROMS/H.E.R.O. (1984) (Activision, John Van Ryzin) (AZ-036-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/hero.bin\n",
      "copying pacman.bin from ./Roms/ROMS/Pac-Man (1982) (Atari, Tod Frye) (CX2646) (PAL).bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/pacman.bin\n",
      "copying demon_attack.bin from ./Roms/ROMS/Demon Attack (Death from Above) (1982) (Imagic, Rob Fulop) (720000-200, 720101-1B, 720101-1C, IA3200, IA3200C, IX-006-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/demon_attack.bin\n",
      "copying mr_do.bin from ./Roms/ROMS/Mr. Do! (1983) (CBS Electronics, Ed English) (4L4478) (PAL).bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/mr_do.bin\n",
      "copying robotank.bin from ./Roms/ROMS/Robot Tank (Robotank) (1983) (Activision, Alan Miller) (AZ-028, AG-028-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/robotank.bin\n",
      "copying skiing.bin from ./Roms/ROMS/Skiing - Le Ski (1980) (Activision, Bob Whitehead) (AG-005, CAG-005, AG-005-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/skiing.bin\n",
      "copying koolaid.bin from ./Roms/ROMS/Kool-Aid Man (Kool Aid Pitcher Man) (1983) (M Network, Stephen Tatsumi, Jane Terjung - Kool Aid) (MT4648) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/koolaid.bin\n",
      "copying laser_gates.bin from ./Roms/ROMS/Laser Gates (AKA Innerspace) (1983) (Imagic, Dan Oliver) (720118-2A, 13208, EIX-007-04I) (PAL).bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/laser_gates.bin\n",
      "copying enduro.bin from ./Roms/ROMS/Enduro (1983) (Activision, Larry Miller) (AX-026, AX-026-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/enduro.bin\n",
      "copying alien.bin from ./Roms/ROMS/Alien (1982) (20th Century Fox Video Games, Douglas 'Dallas North' Neubauer) (11006) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/alien.bin\n",
      "copying seaquest.bin from ./Roms/ROMS/Seaquest (1983) (Activision, Steve Cartwright) (AX-022) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/seaquest.bin\n",
      "copying kaboom.bin from ./Roms/ROMS/Kaboom! (Paddle) (1981) (Activision, Larry Kaplan, David Crane) (AG-010, AG-010-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/kaboom.bin\n",
      "copying beam_rider.bin from ./Roms/ROMS/Beamrider (1984) (Activision - Cheshire Engineering, David Rolfe, Larry Zwick) (AZ-037-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/beam_rider.bin\n",
      "copying breakout.bin from ./Roms/ROMS/Breakout - Breakaway IV (Paddle) (1978) (Atari, Brad Stewart - Sears) (CX2622 - 6-99813, 49-75107) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/breakout.bin\n",
      "copying boxing.bin from ./Roms/ROMS/Boxing - La Boxe (1980) (Activision, Bob Whitehead) (AG-002, CAG-002, AG-002-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/boxing.bin\n",
      "copying asterix.bin from ./Roms/ROMS/Asterix (AKA Taz) (1984) (Atari, Jerome Domurat, Steve Woita) (CX2696).bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/asterix.bin\n",
      "copying asteroids.bin from ./Roms/ROMS/Asteroids (1981) (Atari, Brad Stewart - Sears) (CX2649 - 49-75163) [no copyright] ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/asteroids.bin\n",
      "copying wizard_of_wor.bin from ./Roms/ROMS/Wizard of Wor (1982) (CBS Electronics - Roklan, Joe Hellesen, Joe Wagner) (M8774, M8794) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/wizard_of_wor.bin\n",
      "copying crazy_climber.bin from ./Roms/ROMS/Crazy Climber (1983) (Atari - Roklan, Joe Gaucher, Alex Leavens) (CX2683) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/crazy_climber.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying pitfall.bin from ./Roms/ROMS/Pitfall! - Pitfall Harry's Jungle Adventure (Jungle Runner) (1982) (Activision, David Crane) (AX-018, AX-018-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/pitfall.bin\n",
      "copying pooyan.bin from ./Roms/ROMS/Pooyan (1983) (Konami) (RC 100-X 02) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/pooyan.bin\n",
      "copying private_eye.bin from ./Roms/ROMS/Private Eye (1984) (Activision, Bob Whitehead) (AG-034-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/private_eye.bin\n",
      "copying space_invaders.bin from ./Roms/ROMS/Space Invaders (1980) (Atari, Richard Maurer - Sears) (CX2632 - 49-75153) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/space_invaders.bin\n",
      "copying kung_fu_master.bin from ./Roms/ROMS/Kung-Fu Master (1987) (Activision - Imagineering, Dan Kitchen, Garry Kitchen) (AG-039-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/kung_fu_master.bin\n",
      "copying berzerk.bin from ./Roms/ROMS/Berzerk (1982) (Atari, Dan Hitchens - Sears) (CX2650 - 49-75168) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/berzerk.bin\n",
      "copying krull.bin from ./Roms/ROMS/Krull (1983) (Atari, Jerome Domurat, Dave Staugas) (CX2682) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/krull.bin\n",
      "copying ms_pacman.bin from ./Roms/ROMS/Ms. Pac-Man (1983) (Atari - GCC, Mark Ackerman, Glenn Parker) (CX2675) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/ms_pacman.bin\n",
      "copying fishing_derby.bin from ./Roms/ROMS/Fishing Derby (1980) (Activision, David Crane) (AG-004) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/fishing_derby.bin\n",
      "copying battle_zone.bin from ./Roms/ROMS/Battlezone (1983) (Atari - GCC, Mike Feinstein, Brad Rice) (CX2681) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/battle_zone.bin\n",
      "copying trondead.bin from ./Roms/ROMS/TRON - Deadly Discs (TRON Joystick) (1983) (M Network - INTV - APh Technological Consulting, Jeff Ronne, Brett Stutz) (MT5662) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/trondead.bin\n",
      "copying venture.bin from ./Roms/ROMS/Venture (1982) (Coleco, Joseph Biel) (2457) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/venture.bin\n",
      "copying ice_hockey.bin from ./Roms/ROMS/Ice Hockey - Le Hockey Sur Glace (1981) (Activision, Alan Miller) (AX-012, CAX-012, AX-012-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/ice_hockey.bin\n",
      "copying frostbite.bin from ./Roms/ROMS/Frostbite (1983) (Activision, Steve Cartwright) (AX-031) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/frostbite.bin\n",
      "copying time_pilot.bin from ./Roms/ROMS/Time Pilot (1983) (Coleco - Woodside Design Associates, Harley H. Puthuff Jr.) (2663) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/time_pilot.bin\n",
      "copying freeway.bin from ./Roms/ROMS/Freeway (1981) (Activision, David Crane) (AG-009, AG-009-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/freeway.bin\n",
      "copying phoenix.bin from ./Roms/ROMS/Phoenix (1983) (Atari - GCC, Mike Feinstein, John Mracek) (CX2673) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/phoenix.bin\n",
      "copying riverraid.bin from ./Roms/ROMS/River Raid (1982) (Activision, Carol Shaw) (AX-020, AX-020-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/riverraid.bin\n",
      "copying tennis.bin from ./Roms/ROMS/Tennis - Le Tennis (1981) (Activision, Alan Miller) (AG-007, CAG-007) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/tennis.bin\n",
      "copying bowling.bin from ./Roms/ROMS/Bowling (1979) (Atari, Larry Kaplan - Sears) (CX2628 - 6-99842, 49-75117) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/bowling.bin\n",
      "copying elevator_action.bin from ./Roms/ROMS/Elevator Action (1983) (Atari, Dan Hitchens) (CX26126) (Prototype) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/elevator_action.bin\n",
      "copying pong.bin from ./Roms/ROMS/Video Olympics - Pong Sports (Paddle) (1977) (Atari, Joe Decuir - Sears) (CX2621 - 99806, 6-99806, 49-75104) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/pong.bin\n",
      "copying keystone_kapers.bin from ./Roms/ROMS/Keystone Kapers - Raueber und Gendarm (1983) (Activision, Garry Kitchen - Ariola) (EAX-025, EAX-025-04I - 711 025-725) (PAL).bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/keystone_kapers.bin\n",
      "copying air_raid.bin from ./Roms/ROMS/Air Raid (Men-A-Vision) (PAL) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/air_raid.bin\n",
      "copying king_kong.bin from ./Roms/ROMS/King Kong (1982) (Tigervision - Software Electronics Corporation, Karl T. Olinger - Teldec) (7-001 - 3.60001 VE) (PAL).bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/king_kong.bin\n",
      "copying defender.bin from ./Roms/ROMS/Defender (1982) (Atari, Robert C. Polaro, Alan J. Murphy - Sears) (CX2609 - 49-75186) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/defender.bin\n",
      "copying amidar.bin from ./Roms/ROMS/Amidar (1982) (Parker Brothers, Ed Temple) (PB5310) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/amidar.bin\n",
      "copying chopper_command.bin from ./Roms/ROMS/Chopper Command (1982) (Activision, Bob Whitehead) (AX-015, AX-015-04) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/chopper_command.bin\n",
      "copying double_dunk.bin from ./Roms/ROMS/Double Dunk (Super Basketball) (1989) (Atari, Matthew L. Hubbard) (CX26159) ~.bin to /home/brianadit24/Downloads/AI_Research/rlcourse_env/lib/python3.8/site-packages/atari_py/atari_roms/double_dunk.bin\n"
     ]
    }
   ],
   "source": [
    "!python -m atari_py.import_roms ./Roms/ROMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb98ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'Breakout-v0'\n",
    "env = gym.make(ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4662b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dffe4c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Score: 0.0\n",
      "Episode: 2 Score: 0.0\n",
      "Episode: 3 Score: 0.0\n",
      "Episode: 4 Score: 1.0\n",
      "Episode: 5 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print(f\"Episode: {episode} Score: {score}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d588430",
   "metadata": {},
   "source": [
    "# 3. Vectorize Environment and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2cebcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_atari_env(ENV_NAME, n_envs=4, seed=0)\n",
    "env = VecFrameStack(env, n_stack=4) #Train Multiple Env on Same Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5980125d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "log_path = os.path.join('Training', 'Logs')\n",
    "model = A2C('CnnPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "286d0005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 277      |\n",
      "|    ep_rew_mean        | 1.46     |\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.38    |\n",
      "|    explained_variance | 0.00752  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.164   |\n",
      "|    value_loss         | 0.0315   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 282      |\n",
      "|    ep_rew_mean        | 1.58     |\n",
      "| time/                 |          |\n",
      "|    fps                | 57       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.961   |\n",
      "|    explained_variance | 0.75     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.325   |\n",
      "|    value_loss         | 0.24     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 294      |\n",
      "|    ep_rew_mean        | 1.78     |\n",
      "| time/                 |          |\n",
      "|    fps                | 58       |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 102      |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.09    |\n",
      "|    explained_variance | 0.788    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.0388  |\n",
      "|    value_loss         | 0.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 301      |\n",
      "|    ep_rew_mean        | 1.92     |\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 132      |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 0.938    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -0.0123  |\n",
      "|    value_loss         | 0.0269   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 311      |\n",
      "|    ep_rew_mean        | 2.09     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 163      |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.567    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.0624  |\n",
      "|    value_loss         | 0.0082   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 314      |\n",
      "|    ep_rew_mean        | 2.17     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 193      |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.32    |\n",
      "|    explained_variance | 0.958    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 0.0349   |\n",
      "|    value_loss         | 0.00758  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 313      |\n",
      "|    ep_rew_mean        | 2.22     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 224      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.18    |\n",
      "|    explained_variance | 0.936    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | 0.0797   |\n",
      "|    value_loss         | 0.025    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 313      |\n",
      "|    ep_rew_mean        | 2.24     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 256      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.07    |\n",
      "|    explained_variance | 0.616    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | 0.241    |\n",
      "|    value_loss         | 0.175    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 313      |\n",
      "|    ep_rew_mean        | 2.26     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 287      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.863   |\n",
      "|    explained_variance | 0.886    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.056    |\n",
      "|    value_loss         | 0.0556   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 318      |\n",
      "|    ep_rew_mean        | 2.34     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 318      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.12    |\n",
      "|    explained_variance | 0.864    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.00554  |\n",
      "|    value_loss         | 0.0497   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 333      |\n",
      "|    ep_rew_mean        | 2.68     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 348      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.941   |\n",
      "|    explained_variance | 0.622    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.00552  |\n",
      "|    value_loss         | 0.0292   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 327      |\n",
      "|    ep_rew_mean        | 2.69     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 380      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.383   |\n",
      "|    explained_variance | -0.785   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.123   |\n",
      "|    value_loss         | 0.0616   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 326      |\n",
      "|    ep_rew_mean        | 2.77     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 412      |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.182   |\n",
      "|    explained_variance | 0.884    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.167   |\n",
      "|    value_loss         | 0.107    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 346      |\n",
      "|    ep_rew_mean        | 3.25     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 442      |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.12    |\n",
      "|    explained_variance | 0.863    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.0118   |\n",
      "|    value_loss         | 0.166    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 345       |\n",
      "|    ep_rew_mean        | 3.25      |\n",
      "| time/                 |           |\n",
      "|    fps                | 63        |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 472       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00411  |\n",
      "|    explained_variance | 0.913     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | -4.41e-05 |\n",
      "|    value_loss         | 0.0261    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 338       |\n",
      "|    ep_rew_mean        | 3.11      |\n",
      "| time/                 |           |\n",
      "|    fps                | 63        |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 504       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0604   |\n",
      "|    explained_variance | 0.969     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | -0.000331 |\n",
      "|    value_loss         | 0.00838   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 266      |\n",
      "|    ep_rew_mean        | 1.64     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 537      |\n",
      "|    total_timesteps    | 34000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00747 |\n",
      "|    explained_variance | 0.976    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 1.37e-05 |\n",
      "|    value_loss         | 0.000908 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 265       |\n",
      "|    ep_rew_mean        | 1.61      |\n",
      "| time/                 |           |\n",
      "|    fps                | 63        |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 569       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00328  |\n",
      "|    explained_variance | 0.813     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | -1.85e-05 |\n",
      "|    value_loss         | 0.0134    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 270      |\n",
      "|    ep_rew_mean        | 1.75     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 603      |\n",
      "|    total_timesteps    | 38000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0127  |\n",
      "|    explained_variance | 0.961    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 1.16e-05 |\n",
      "|    value_loss         | 0.00737  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 294      |\n",
      "|    ep_rew_mean        | 2.17     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2000     |\n",
      "|    time_elapsed       | 635      |\n",
      "|    total_timesteps    | 40000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0786  |\n",
      "|    explained_variance | 0.0559   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.00265  |\n",
      "|    value_loss         | 0.224    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 305      |\n",
      "|    ep_rew_mean        | 2.38     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2100     |\n",
      "|    time_elapsed       | 668      |\n",
      "|    total_timesteps    | 42000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0502  |\n",
      "|    explained_variance | -0.0737  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2099     |\n",
      "|    policy_loss        | 0.00031  |\n",
      "|    value_loss         | 0.00385  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 306      |\n",
      "|    ep_rew_mean        | 2.42     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2200     |\n",
      "|    time_elapsed       | 702      |\n",
      "|    total_timesteps    | 44000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.131   |\n",
      "|    explained_variance | 0.68     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2199     |\n",
      "|    policy_loss        | 0.00983  |\n",
      "|    value_loss         | 0.193    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 321      |\n",
      "|    ep_rew_mean        | 2.71     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2300     |\n",
      "|    time_elapsed       | 737      |\n",
      "|    total_timesteps    | 46000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0521  |\n",
      "|    explained_variance | 0.826    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2299     |\n",
      "|    policy_loss        | -0.00706 |\n",
      "|    value_loss         | 0.173    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 331      |\n",
      "|    ep_rew_mean        | 2.87     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2400     |\n",
      "|    time_elapsed       | 766      |\n",
      "|    total_timesteps    | 48000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.168   |\n",
      "|    explained_variance | 0.958    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2399     |\n",
      "|    policy_loss        | 0.00337  |\n",
      "|    value_loss         | 0.0677   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 371      |\n",
      "|    ep_rew_mean        | 3.63     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 796      |\n",
      "|    total_timesteps    | 50000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.125   |\n",
      "|    explained_variance | 0.985    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | 0.0008   |\n",
      "|    value_loss         | 0.0208   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 408      |\n",
      "|    ep_rew_mean        | 4.38     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2600     |\n",
      "|    time_elapsed       | 826      |\n",
      "|    total_timesteps    | 52000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.114   |\n",
      "|    explained_variance | 0.972    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2599     |\n",
      "|    policy_loss        | -0.0022  |\n",
      "|    value_loss         | 0.0177   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 439      |\n",
      "|    ep_rew_mean        | 4.96     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2700     |\n",
      "|    time_elapsed       | 859      |\n",
      "|    total_timesteps    | 54000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.236   |\n",
      "|    explained_variance | 0.941    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2699     |\n",
      "|    policy_loss        | 0.02     |\n",
      "|    value_loss         | 0.0282   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 442      |\n",
      "|    ep_rew_mean        | 5.02     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 893      |\n",
      "|    total_timesteps    | 56000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0564  |\n",
      "|    explained_variance | 0.937    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | 0.000948 |\n",
      "|    value_loss         | 0.0792   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 440      |\n",
      "|    ep_rew_mean        | 4.96     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 2900     |\n",
      "|    time_elapsed       | 926      |\n",
      "|    total_timesteps    | 58000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0148  |\n",
      "|    explained_variance | 0.854    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2899     |\n",
      "|    policy_loss        | 0.000504 |\n",
      "|    value_loss         | 0.0767   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 434      |\n",
      "|    ep_rew_mean        | 4.81     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 965      |\n",
      "|    total_timesteps    | 60000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00903 |\n",
      "|    explained_variance | 0.962    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | 6.25e-05 |\n",
      "|    value_loss         | 0.0234   |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 439       |\n",
      "|    ep_rew_mean        | 4.87      |\n",
      "| time/                 |           |\n",
      "|    fps                | 61        |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 1004      |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.00367  |\n",
      "|    explained_variance | 0.175     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | -0.000387 |\n",
      "|    value_loss         | 0.368     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 430      |\n",
      "|    ep_rew_mean        | 4.68     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 1037     |\n",
      "|    total_timesteps    | 64000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0774  |\n",
      "|    explained_variance | 0.938    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 0.00289  |\n",
      "|    value_loss         | 0.0466   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 422      |\n",
      "|    ep_rew_mean        | 4.6      |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 3300     |\n",
      "|    time_elapsed       | 1069     |\n",
      "|    total_timesteps    | 66000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0907  |\n",
      "|    explained_variance | 0.953    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3299     |\n",
      "|    policy_loss        | -0.0116  |\n",
      "|    value_loss         | 0.0661   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 424      |\n",
      "|    ep_rew_mean        | 4.67     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 1100     |\n",
      "|    total_timesteps    | 68000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.343   |\n",
      "|    explained_variance | 0.825    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 0.0422   |\n",
      "|    value_loss         | 0.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 419      |\n",
      "|    ep_rew_mean        | 4.57     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 1132     |\n",
      "|    total_timesteps    | 70000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.00921 |\n",
      "|    explained_variance | 0.935    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 0.000105 |\n",
      "|    value_loss         | 0.108    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 415      |\n",
      "|    ep_rew_mean        | 4.65     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 1164     |\n",
      "|    total_timesteps    | 72000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.069   |\n",
      "|    explained_variance | 0.888    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | -0.00102 |\n",
      "|    value_loss         | 0.0623   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 414      |\n",
      "|    ep_rew_mean        | 4.57     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 3700     |\n",
      "|    time_elapsed       | 1195     |\n",
      "|    total_timesteps    | 74000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.383   |\n",
      "|    explained_variance | 0.696    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3699     |\n",
      "|    policy_loss        | -0.0341  |\n",
      "|    value_loss         | 0.0337   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 422      |\n",
      "|    ep_rew_mean        | 4.74     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 3800     |\n",
      "|    time_elapsed       | 1227     |\n",
      "|    total_timesteps    | 76000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.122   |\n",
      "|    explained_variance | 0.969    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | -0.00299 |\n",
      "|    value_loss         | 0.0354   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 417      |\n",
      "|    ep_rew_mean        | 4.59     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 1258     |\n",
      "|    total_timesteps    | 78000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.172   |\n",
      "|    explained_variance | 0.589    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | 0.107    |\n",
      "|    value_loss         | 0.211    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 437      |\n",
      "|    ep_rew_mean        | 4.95     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 1289     |\n",
      "|    total_timesteps    | 80000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.227   |\n",
      "|    explained_variance | 0.652    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | 0.01     |\n",
      "|    value_loss         | 0.0625   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 448      |\n",
      "|    ep_rew_mean        | 5.16     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 4100     |\n",
      "|    time_elapsed       | 1320     |\n",
      "|    total_timesteps    | 82000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0335  |\n",
      "|    explained_variance | -2.13    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4099     |\n",
      "|    policy_loss        | 0.035    |\n",
      "|    value_loss         | 0.243    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 461      |\n",
      "|    ep_rew_mean        | 5.43     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 1351     |\n",
      "|    total_timesteps    | 84000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.101   |\n",
      "|    explained_variance | 0.949    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | 0.00227  |\n",
      "|    value_loss         | 0.0101   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 474      |\n",
      "|    ep_rew_mean        | 5.7      |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 1382     |\n",
      "|    total_timesteps    | 86000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.369   |\n",
      "|    explained_variance | 0.992    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | -0.0153  |\n",
      "|    value_loss         | 0.00776  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 471      |\n",
      "|    ep_rew_mean        | 5.68     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 1414     |\n",
      "|    total_timesteps    | 88000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.211   |\n",
      "|    explained_variance | 0.982    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 0.00442  |\n",
      "|    value_loss         | 0.011    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 458      |\n",
      "|    ep_rew_mean        | 5.45     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 1446     |\n",
      "|    total_timesteps    | 90000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.186   |\n",
      "|    explained_variance | 0.955    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | -0.0154  |\n",
      "|    value_loss         | 0.0205   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 447      |\n",
      "|    ep_rew_mean        | 5.24     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 4600     |\n",
      "|    time_elapsed       | 1476     |\n",
      "|    total_timesteps    | 92000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.185   |\n",
      "|    explained_variance | 0.985    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4599     |\n",
      "|    policy_loss        | 0.0204   |\n",
      "|    value_loss         | 0.0141   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 449      |\n",
      "|    ep_rew_mean        | 5.27     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 4700     |\n",
      "|    time_elapsed       | 1508     |\n",
      "|    total_timesteps    | 94000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.23    |\n",
      "|    explained_variance | 0.934    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4699     |\n",
      "|    policy_loss        | -0.00767 |\n",
      "|    value_loss         | 0.0497   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 443      |\n",
      "|    ep_rew_mean        | 5.16     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 4800     |\n",
      "|    time_elapsed       | 1539     |\n",
      "|    total_timesteps    | 96000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.29    |\n",
      "|    explained_variance | 0.907    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4799     |\n",
      "|    policy_loss        | -0.0024  |\n",
      "|    value_loss         | 0.0294   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 444      |\n",
      "|    ep_rew_mean        | 5.13     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 4900     |\n",
      "|    time_elapsed       | 1570     |\n",
      "|    total_timesteps    | 98000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0835  |\n",
      "|    explained_variance | 0.8      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4899     |\n",
      "|    policy_loss        | 0.0404   |\n",
      "|    value_loss         | 0.112    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 452      |\n",
      "|    ep_rew_mean        | 5.34     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 5000     |\n",
      "|    time_elapsed       | 1601     |\n",
      "|    total_timesteps    | 100000   |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0635  |\n",
      "|    explained_variance | 0.87     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4999     |\n",
      "|    policy_loss        | 0.0191   |\n",
      "|    value_loss         | 0.223    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7fbed0033a30>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14a7ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_path = os.path.join('Training', 'SavedModels', 'A2C_Breakout_Model')\n",
    "model.save(a2c_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b119917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20420617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = A2C.load(a2c_path, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9da96e",
   "metadata": {},
   "source": [
    "# 5. Evaluate Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "226b7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_atari_env(ENV_NAME, n_envs=1, seed=0) # Change to Single for Evaluate Model\n",
    "env = VecFrameStack(env, n_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdb4de2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.7, 2.968164415931166)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7f227b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6f694d",
   "metadata": {},
   "source": [
    "<b>Conclusion:</b> I think maybe we need to increase total_timesteps on Training Agent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlcourse_env",
   "language": "python",
   "name": "rlcourse_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
